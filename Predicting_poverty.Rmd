---
title: "Predicting_poverty"
author: "Farooq Qaiser"
date: "February 14, 2018"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

# Admin

## set seed

```{r}

## set the seed to make rmd reproducible
set.seed(123)

```


## load libraries 

```{r}

# don't want this mask margin from ggplot2
library(randomForest)

library(dplyr)
library(tidyr)
library(ggplot2)

library(dummies)
library(keras)

```


## load data

```{r}

data_loc = "/home/fqaiser94/poverty_data"

files = list.files(path = data_loc, pattern = '.*hhold.*train.*')	
file_paths = paste0(data_loc, '/', files)

for(file in file_paths) {
  
  print(file)
  
  raw_data = read.csv(
    file = file, 
    header = TRUE, 
    stringsAsFactors = FALSE
    )
  
}

raw_data

```

# EDA

## column names

```{r}

colnames(raw_data)

```

The majority of the columns' names have been masked. 
id, country, poor are the only ones I see which haven't been masked. 

## missing data

```{r}

ggplot_missing <- function(x){
  
  x %>% 
    is.na %>%
    reshape2::melt() %>%
    ggplot(
      aes(x = Var2, y = Var1)) +
    geom_raster(
      aes(fill = value)) +
    scale_fill_grey(
      name = "",
      labels = c("Present","Missing")) +
    theme_minimal() + 
    theme(
      axis.ticks = element_line(), 
      axis.text.x  = element_blank()) + 
    labs(
      x = "Variables",
      y = "Rows")
}

ggplot_missing(raw_data)

```

Absolutely no missing data. 

## class balance

```{r}

raw_data %>%
  ggplot(mapping = aes(x = poor)) +
  geom_bar() + 
  theme_minimal()

```

fairly balanced dataset

# Modelling

## preprocess data

```{r}

unique(raw_data$poor)

```

Our target variable appears to be encoded as strings. Let's double check that. 

```{r}

sapply(select(raw_data, poor), class)

```

yup, character.  

```{r}

raw_data$poor = ifelse(raw_data$poor=="True", TRUE, FALSE)
sapply(select(raw_data, poor), class)


```

changed to boolean

```{r}

which(raw_data=="True", arr.ind = TRUE)
which(raw_data=="False", arr.ind = TRUE)

```

double checked and verified that there are no other columns where True/False is encoded as strings

```{r}

unique(sapply(raw_data, class))

```

got four types of features in our data

```{r}

filter_by_column_type = function(df, type) {
  
  ind <- sapply(df, type)
  
  return(df[ind])
  
}

filter_by_column_type(head(raw_data), is.numeric) # integer or double (numeric)
filter_by_column_type(head(raw_data), is.character)


```

only 4 numeric (integer or double) columns (excluding id column)

```{r}

model_data = raw_data

```

create new df for preprocessed data

```{r}

# standardize numeric features
standardize <- function(df, omit_columns) {
 
  # identify columns for standardization
  ind = sapply(df, is.numeric)
  
  # omit specific columns for standardization
  ind[which(colnames(df) %in% omit_columns)] <- FALSE

  # standardize columns
  df[ind] = lapply(df[ind], scale)
  
  return(df)
}

model_data <- standardize(
  df = model_data, 
  omit_columns = 'id')


```

standardize numeric columns (excluding the id column)

```{r}

# OHE categorical features
model_data <- dummy.data.frame(
  data = model_data, 
  dummy.classes = c('character'),
  sep="_")

```

one hot encode character columns

```{r}

rownames(model_data) <- model_data$id

# model_data <- subset(model_data, select = -c(id))

```

remove id column

## logistic regression

insert code here

## random forests model

```{r}

## 75% of the sample size
sample_size <- floor(0.75 * nrow(model_data))

train_ind <- sample(seq_len(nrow(model_data)), size = sample_size)

train <- model_data[train_ind, -model_data$id]
test <- model_data[-train_ind, -model_data$id]

```

split into train and test samples

```{r}

# rf = randomForest(
#   factor(poor) ~ . , 
#   data = train 
#   )
# 
# rf

```

```{r}

# plot(rf)

```

```{r}

# varImpPlot(rf)

```

## lightGBM

useful resources:  
- https://www.kaggle.com/andrewmvd/lightgbm-in-r  
- https://github.com/Microsoft/LightGBM/tree/master/R-package  

## deep learning

recommended resources for deep learning in keras:  
- https://www.amazon.com/Deep-Learning-R-Francois-Chollet/dp/161729554X  
- https://github.com/rstudio/cheatsheets/raw/master/keras.pdf  
- https://www.datacamp.com/community/tutorials/keras-r-deep-learning  
- https://www.linkedin.com/pulse/finally-deep-learning-keras-tensorflow-r-richard-wanjohi-ph-d/  

```{r}

x_train <- data.matrix(select(train, -poor))
x_test <- data.matrix(select(test, -poor))

y_train = to_categorical(train$poor)
y_test = to_categorical(test$poor)

```

```{r}

model <- keras_model_sequential() 

model %>% 
  layer_dense(units = 3000, activation = 'relu', input_shape = c(ncol(x_train))) %>% 
  layer_dropout(rate = 0.4) %>%
  layer_dense(units = 1000, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 512, activation = 'relu') %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 256, activation = 'relu') %>%
  layer_dropout(rate = 0.1) %>%
  layer_dense(units = 50, activation = 'relu') %>%
  layer_dropout(rate = 0.05) %>%
  # softmax guarantees the output to be between 0 and 1 
  layer_dense(units = 2, activation = 'softmax') 

```

arbitrary deep learning architecture  

consider using a multiscale architecture

```{r}

model %>% compile(
  # loss = 'categorical_crossentropy',
  loss = 'binary_crossentropy', # this is the metric used for the competition
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)

```

Other loss functions available here: https://keras.io/losses/

```{r}

history <- model %>% 
  fit(
    x = x_train, 
    y = y_train, 
    epochs = 5,  #30, 
    batch_size = 128, 
    validation_split = 0.2
)

plot(history)

```

```{r}

model %>% 
  evaluate(x_test, y_test)

```


```{r}

# Plot the model loss of the training data
plot(
  history$metrics$loss, 
  main="Model Loss", 
  xlab = "epoch", 
  ylab="loss", 
  col="blue", 
  type="l")

# Plot the model loss of the test data
lines(
  history$metrics$val_loss, 
  col="green")

# Add legend
legend(
  "topright", 
  c("train","test"), 
  col=c("blue", "green"), 
  lty=c(1,1))

```


```{r}

# Plot the model accuracy
plot(
  history$metrics$acc, 
  main="Model Accuracy", 
  xlab = "epoch", 
  ylab="accuracy", 
  col="blue", 
  type="l")

lines(
  history$metrics$val_acc, 
  col="green")

legend(
  "bottomright", 
  c("train","test"), 
  col=c("blue", "green"), 
  lty=c(1,1))

```

### predictions

```{r}

predictions <- model %>%
  # make predictions
  predict_proba(x=x_test) %>%
  # convert to df
  data.frame() %>%
  rename(not_poor=X1, poor=X2) %>%
  # add back country
  mutate(country='A') %>%
  # add back id
  bind_cols(model_data[-train_ind, -model_data$id]) %>%
  # we only want the probability that p = 1 (not p = 0)
  select(id, country, poor)

head(predictions)

```

### interpreting the model

useful resources:  
- http://www.f1-predictor.com/model-interpretability-with-shap/?utm_source=linkedin&utm_medium=post&utm_campaign=shap 
- 

insert SHAP/LIME code

## ensemble

combine multiple predictors  

useful resources:  
- https://www.analyticsvidhya.com/blog/2017/02/introduction-to-ensembling-along-with-implementation-in-r/  


### correlation check 

check models are relatively uncorrelated  

### average

```{r}

#Predicting the probabilities
testSet$pred_rf_prob <- predict(
  object = model_rf, 
  testSet[,predictors], 
  type='prob')

testSet$pred_knn_prob <- predict(
  object = model_knn, 
  testSet[,predictors],
  type='prob')

testSet$pred_lr_prob <- predict(
  object = model_lr, 
  testSet[,predictors],
  type='prob')

# taking average of predictions
testSet$pred_avg <-(
  testSet$pred_rf_prob$Y + testSet$pred_knn_prob$Y + testSet$pred_lr_prob$Y)/3

# splitting into binary classes at 0.5
testSet$pred_avg<-as.factor(
  ifelse(
    testSet$pred_avg>0.5,
    'Y',
    'N'))

```

### weighted average

```{r}

# Taking weighted average of predictions
testSet$pred_weighted_avg <- (testSet$pred_rf_prob$Y*0.25) + 
  (testSet$pred_knn_prob$Y*0.25) +
  (testSet$pred_lr_prob$Y*0.5)

#Splitting into binary classes at 0.5
testSet$pred_weighted_avg <- as.factor(
  ifelse(
    testSet$pred_weighted_avg>0.5, 
    'Y',
    'N'))

```

### stacking  

